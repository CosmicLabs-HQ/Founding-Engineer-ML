# Founding AI/ML Engineer – Efficient Models x Real-World Deployment x Edge-Aware Intelligence

**Location:** Brooklyn / San Francisco (Relocation Supported)
**Type:** Full-time | Competitive Pay + Equity
**Start Date:** ASAP

---

## What You’ll Build

* Design and train compact, high-performance AI models that run in constrained environments—under tight latency, memory, bandwidth, and power ceilings
* Fine-tune and optimize models using quantization, distillation, pruning, and structured sparsity techniques
* Convert and deploy models across a range of real-world hardware targets: embedded ARM, edge GPUs, edge CPUs, radios, mobile-class silicon
* Own the end-to-end ML lifecycle: from architectural design and training to evaluation, system integration, and post-deployment debugging
* Build tooling and automation to monitor model performance across volatile, distributed systems
* Collaborate with embedded and infra engineers to ensure tight coordination between model behavior and system-level constraints
* Help shape our AI/ML architecture and long-term roadmap while writing and shipping real code every day

---

## What You Bring

* 4+ years of experience in ML research or applied AI
* Strong foundation in deep learning (PyTorch, JAX, or TensorFlow) and model design from first principles
* Experience training or fine-tuning small- to mid-scale models (language, vision, multi-modal, or agentic)
* Deep familiarity with model optimization techniques: quantization, pruning, LoRA, distillation, etc.
* Hands-on experience with **ONNX**, **Core ML Tools**, **TVM**, or similar frameworks for hardware-aware model conversion and deployment
* Proven ability to deploy and optimize models across diverse hardware (Apple Silicon, ARM, GPUs, NPUs, etc.)
* Comfortable with the state of the art—transformer variants, efficient architectures, emerging sparsity techniques, and real-world robustness challenges
* Strong debugging and experimentation skills across data, model, and system layers
* Able to work independently on hard open-ended problems, and collaborate across disciplines with clarity and speed

---

## Bonus Points

* Publications or open-source contributions in model efficiency, deployment tooling, or systems-aware ML
* Prior experience building models for edge use cases or latency-sensitive environments
* Familiarity with TinyML, quantized runtime stacks, or inference under low-power conditions
* Experience with real-time agents or adaptive inference systems
* Background in autonomy, robotics, networking, or embedded AI

---

## Why Cosmic Labs

We're building AI infrastructure where resilience matters more than size, and speed matters more than scale. Our systems operate in environments where power is limited, compute is volatile, and downtime breaks mission-critical decisions.

We're not optimizing cloud inference—we're designing **self-reliant AI systems** that adapt, recover, and operate under pressure. If you're obsessed with **how to make models smaller, faster, smarter**, and care about making AI work beyond the lab—we want to talk.

---

## How to Apply

Email the following to `team@cosmiclabs.io`:

**Subject line:**
`Founding AI/ML Engineer / [Your Name]`

**In the body:**

* Your name
* Why this role and why Cosmic Labs
* What you bring technically
* Soonest available start date
* Education and years of experience
* Work eligibility status

**Attachment:**

* PDF resume

**Deadline:** Applications reviewed on a rolling basis. Final deadline is EOD August 28, 2025.
